# 第3回：来月の売上を当てろ！ChatGPTに予測させるプロンプト術（10分）

## オープニング（0:00-0:30）

### 導入フレーズ
「みなさん、こんにちは。売上データ分析×ChatGPT研修の第3回です。

これまで、データの分析とグラフ化を学んできました。

今日のテーマは『来月の売上を当てろ！』です。

『来月どれくらい売れる？』という問いに、AIが数字と理由で答えます。

統計学の知識は不要。ChatGPTが予測モデルを構築し、その根拠まで説明してくれます。」

## 1. 予測の重要性と現状の課題（0:30-1:30）

### Before状態の現実
「現在、多くの企業で売上予測はこんな方法で行われています：

- 前年同月の実績を見て、感覚的に10%増減
- 直近3ヶ月の平均を来月の予測値とする
- エクセルで簡単な回帰分析（でも根拠の説明が難しい）

結果として、予測精度は平均15-20%の誤差。
在庫過多や機会損失につながっています。」

### After状態のビジョン
「今日の10分で実現できること：

- 統計的根拠のある予測値の算出
- 予測の信頼区間の提示
- なぜその予測値になったかの説明
- 誤差率を10%以内に改善

これらすべてを、ChatGPTとの対話だけで実現します。」

## 2. 基本的な予測の実演（1:30-4:30）

### データの確認と準備
「まず、予測に使うデータを確認しましょう。

sales_data_monthly.csvには過去24ヶ月分のデータが含まれています。

ChatGPTにファイルをアップロードして、こう聞いてみます：

『このデータの基本統計量と、時系列での傾向を教えてください』

ChatGPTの回答：
- 平均売上：500万円
- 標準偏差：80万円
- トレンド：緩やかな上昇傾向（月平均2%成長）
- 季節性：7月と12月にピーク」

### シンプルな予測プロンプト
「では、最初の予測をしてもらいましょう。

プロンプト：
『このデータから売上の季節傾向をもとに、来月（2024年1月）の売上を予測するPythonコードを生成し、その根拠も説明してください。』

ChatGPTが生成したコードを見てみましょう。」

### 生成されたコードの解説
「ChatGPTが提供してくれたコードです：

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from statsmodels.tsa.seasonal import seasonal_decompose
import matplotlib.pyplot as plt

# データ読み込み
df = pd.read_csv('sales_data_monthly.csv')
df['Date'] = pd.to_datetime(df['Month'])
df.set_index('Date', inplace=True)

# 時系列分解
decomposition = seasonal_decompose(df['Sales'], model='additive', period=12)

# トレンド成分での予測
X = np.arange(len(df)).reshape(-1, 1)
y = df['Sales'].values

model = LinearRegression()
model.fit(X, y)

# 来月の予測
next_month_index = len(df)
prediction = model.predict([[next_month_index]])[0]

# 季節調整
seasonal_factor = decomposition.seasonal.iloc[-12]  # 前年同月の季節要因
adjusted_prediction = prediction + seasonal_factor

print(f'来月の売上予測: {adjusted_prediction:,.0f}円')
print(f'予測の根拠:')
print(f'- トレンドベース予測: {prediction:,.0f}円')
print(f'- 季節調整値: {seasonal_factor:,.0f}円')
```

重要なのは、単なる数値だけでなく、根拠も示されることです。」

### 予測結果の解釈
「実行結果を見てください：

来月の売上予測: 5,450,000円
予測の根拠:
- トレンドベース予測: 5,200,000円
- 季節調整値: +250,000円

ChatGPTは、トレンドと季節性を分離して、それぞれの影響を明確に示してくれました。」

## 3. 予測結果の解釈と活用（4:30-7:00）

### 予測結果の読み解き方
「予測値が出たら、それをどう解釈するかが重要です。

予測結果例：
来月の売上予測: 5,450,000円
予測の根拠:
- トレンドベース予測: 5,200,000円
- 季節調整値: +250,000円

この結果から分かること：
1. 基本的には成長傾向が続いている（5,200万円）
2. 季節要因で25万円のプラス効果
3. 全体として前月より若干増加の見込み」

### 予測の信頼性を判断する
「予測をどこまで信用するかの判断基準：

**高い信頼性の予測：**
- 過去のパターンと一致している
- 季節性が明確に現れている
- 外部要因（キャンペーンなど）を考慮済み

**注意が必要な予測：**
- 過去にない大きな変動を予測している
- データが少ない期間での予測
- 市場環境が大きく変わった時期」

### 実際の意思決定への活用
「予測結果を実務でどう使うか：

在庫計画：
- 予測値+10%を仕入れ目安に
- 季節商品は早めの準備を

人員配置：
- 売上増加予測なら人員を増強
- 減少予測なら効率化を検討

マーケティング：
- 予測が低い月は追加施策を企画
- 好調な月はさらに伸ばす戦略を」

### 異常値や外部要因の考慮
「実務では、異常値や外部要因も考慮する必要があります。

プロンプト例：
『2023年3月にキャンペーンで売上が異常に高かったことを考慮して、予測を修正してください』

ChatGPTは異常値を除外したり、重み付けを調整したりして、より現実的な予測を提供してくれます。」

## 4. 予測精度の検証と改善（7:00-8:30）

### バックテストの実施
「予測モデルの精度を確認する方法を学びましょう。

プロンプト：
『過去6ヶ月分を予測して実績と比較し、予測精度（MAPE）を計算してください』

ChatGPTが実行してくれる検証：
- 各月の予測値vs実績値
- 平均絶対誤差率（MAPE）の計算
- 最も誤差が大きかった月の分析」

### 精度改善のテクニック
「予測精度を上げるためのテクニック：

1. データ期間の調整
   『直近12ヶ月のデータのみで予測してください』

2. 外部データの追加
   『気温データも考慮に入れて予測してください』

3. アンサンブル予測
   『3つのモデルの平均値を最終予測値としてください』

**GPTsに保存しておくべき予測改善スクリプト：**
```python
# 予測精度向上のための前処理
def improve_forecast(df):
    # 外れ値除去
    Q1 = df['Sales'].quantile(0.25)
    Q3 = df['Sales'].quantile(0.75)
    IQR = Q3 - Q1
    df = df[(df['Sales'] >= Q1 - 1.5*IQR) & (df['Sales'] <= Q3 + 1.5*IQR)]
    
    # 移動平均でスムージング
    df['Sales_smooth'] = df['Sales'].rolling(3, center=True).mean()
    
    return df
```

これらをGPTsに事前設定することで、誤差率を15%→10%以下に改善できます。」

## 5. 実務での活用方法（8:30-9:30）

### 予測レポートの自動生成
「実務では、予測値だけでなくレポートも必要です。

プロンプト：
『来月の売上予測レポートを以下の構成で作成してください：
1. エグゼクティブサマリー
2. 予測値と信頼区間
3. 予測の根拠と使用モデル
4. リスク要因
5. 推奨アクション』

ChatGPTは、経営層向けの分かりやすいレポートを生成してくれます。」

### シナリオ分析
「さらに、複数シナリオでの予測も可能です：

『楽観・現実・悲観の3シナリオで来月の売上を予測し、それぞれの確率も示してください』

結果例：
- 楽観シナリオ：580万円（確率20%）
- 現実シナリオ：545万円（確率60%）
- 悲観シナリオ：510万円（確率20%）」

## 6. まとめと次回予告（9:30-10:00）

### 本日の成果
「今日学んだことをまとめます：

1. ChatGPTに予測モデルを構築させる方法
2. 複数の予測手法の比較と選択
3. 予測精度の検証と改善
4. 実務で使える予測レポートの作成

これで、根拠のある売上予測が誰でもできるようになりました。

予測精度が5%改善するだけで、在庫コストは大幅に削減できます。」

### 次回予告
「次回は、これまでの分析結果を『Looker Studioで自動更新ダッシュボード』にする方法を学びます。

一度設定すれば、毎月自動で更新される夢のようなダッシュボードが完成します。

PowerPointでの資料作成から解放される日が来ます。

それでは、今日学んだ予測手法を、ぜひ実際のデータで試してみてください。

第3回の講座は以上です。ありがとうございました！」

---

## 講師用メモ

### 重要な伝達事項
- 予測は100%当たらないことを前提に
- 複数手法の比較が重要
- 現場の知見との組み合わせが鍵

### デモの準備
- 複数期間のデータセットを準備
- わざと異常値を含むデータも用意
- 予測が外れた例も正直に見せる

### 質疑応答の準備
- Q: 季節性がない商品の場合は？
- A: トレンドモデルのみ使用、または外部要因を追加

- Q: 新商品の予測は？
- A: 類似商品のデータを参考に、ChatGPTに類推させる

---

## 上級テクニック（経験者向け）

### GPTsで予測モデルを事前設定
「経験を積んだ方は、ChatGPTのGPTs機能に予測モデルを事前にアップロードしておくことで、
毎回同じ精度の高い予測が可能になります。

**GPTsにアップロードすべき予測モデル：**
1. 時系列分解スクリプト
2. Prophet予測モデル
3. ARIMA自動選択スクリプト
4. アンサンブル予測スクリプト

これにより、CSVをアップロードするだけで、
複数の予測手法を自動比較し、最適な予測値を提示してくれます。

### より精度の高い予測モデル
「高度な予測モデルを使いたい場合のプロンプト：

『Prophet、ARIMA、機械学習の3つの手法で売上予測を行い、それぞれの予測値と信頼区間を比較するコードを作成してください。最も精度が高い手法を推奨してください。』

### 複数モデルの比較コード例
```python
# 3つの予測手法の実装
from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA
from sklearn.ensemble import RandomForestRegressor

# Prophet予測
prophet_model = Prophet(yearly_seasonality=True, weekly_seasonality=False)
prophet_df = df.reset_index()[['Date', 'Sales']].rename(columns={'Date': 'ds', 'Sales': 'y'})
prophet_model.fit(prophet_df)
future = prophet_model.make_future_dataframe(periods=1, freq='M')
forecast = prophet_model.predict(future)
prophet_pred = forecast.iloc[-1]['yhat']

# ARIMA予測
arima_model = ARIMA(df['Sales'], order=(1,1,1))
arima_result = arima_model.fit()
arima_pred = arima_result.forecast(steps=1)[0]

print('予測結果の比較:')
print(f'Prophet: {prophet_pred:,.0f}円 (信頼区間: ±8%)')
print(f'ARIMA: {arima_pred:,.0f}円 (信頼区間: ±10%)')
print(f'機械学習: {ml_pred:,.0f}円 (信頼区間: ±7%)')
```

複数の手法を比較することで、より信頼性の高い予測が可能になります。」